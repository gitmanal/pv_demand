{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d259f4-deb2-449f-8756-bb652fecf25c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Imports and Setup\n",
    "import fireducks.pandas as pd\n",
    "import numpy as np\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# MLflow setup\n",
    "mlflow.set_tracking_uri(\"http://localhost:5000\")\n",
    "mlflow.set_experiment('SARIMAX_Example')\n",
    "\n",
    "# Load data\n",
    "df = pd.read_parquet('../data/sequences.parquet')\n",
    "df['TIME'] = pd.to_datetime(df['TIME'])\n",
    "df.set_index('TIME', inplace=True)\n",
    "\n",
    "# Parameters\n",
    "SEQUENCE_ID = 1  # Example with one sequence\n",
    "TRAIN_SIZE = 168  # 7 days\n",
    "VAL_SIZE = 48    # 2 days\n",
    "TEST_SIZE = 24   # 1 day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3811f831-c1a7-4bfa-8ca4-a2105f3d001c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Define simpler model configurations\n",
    "model_configs = [\n",
    "    {\n",
    "        'name': 'simple_model',\n",
    "        'order': (1, 0, 0),  # Simplified order\n",
    "        'seasonal_order': (0, 0, 0, 0),  # Remove seasonality initially\n",
    "        'lags': [1]\n",
    "    },\n",
    "    {\n",
    "        'name': 'base_model',\n",
    "        'order': (1, 0, 1),  # Simple ARIMA\n",
    "        'seasonal_order': (0, 0, 0, 0),  # No seasonality\n",
    "        'lags': [1, 2]\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a0605eb-186d-4c0e-874d-edf20357b1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Define preprocessing function with more robust scaling\n",
    "def preprocess_data(data):\n",
    "    \"\"\"Preprocess sequence data\"\"\"\n",
    "    # Remove outliers\n",
    "    Q1 = data['Power'].quantile(0.25)\n",
    "    Q3 = data['Power'].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    data = data[\n",
    "        (data['Power'] >= Q1 - 1.5 * IQR) &\n",
    "        (data['Power'] <= Q3 + 1.5 * IQR)\n",
    "    ].copy()\n",
    "    \n",
    "    # Scale data\n",
    "    scaler = StandardScaler()\n",
    "    data['Power_scaled'] = scaler.fit_transform(data[['Power']])\n",
    "    \n",
    "    return data, scaler\n",
    "\n",
    "# Get sequence data\n",
    "sequence_data = df[df['sequence'] == SEQUENCE_ID].copy()\n",
    "sequence_data, scaler = preprocess_data(sequence_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ea2b00-3e33-4578-ad04-c7e4118b73bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Training and evaluation with improved error handling\n",
    "for config in model_configs:\n",
    "    # Start MLflow run\n",
    "    with mlflow.start_run(run_name=f\"sequence_{SEQUENCE_ID}_{config['name']}\"):\n",
    "        try:\n",
    "            # Log parameters\n",
    "            mlflow.log_params({\n",
    "                'sequence': SEQUENCE_ID,\n",
    "                'model_name': config['name'],\n",
    "                'order_p': config['order'][0],\n",
    "                'order_d': config['order'][1],\n",
    "                'order_q': config['order'][2],\n",
    "                'seasonal_P': config['seasonal_order'][0],\n",
    "                'seasonal_D': config['seasonal_order'][1],\n",
    "                'seasonal_Q': config['seasonal_order'][2],\n",
    "                'seasonal_period': config['seasonal_order'][3],\n",
    "                'lags': config['lags'],\n",
    "                'train_size': TRAIN_SIZE,\n",
    "                'val_size': VAL_SIZE,\n",
    "                'test_size': TEST_SIZE\n",
    "            })\n",
    "            \n",
    "            # Split data\n",
    "            train_data = sequence_data['Power_scaled'][:TRAIN_SIZE]\n",
    "            val_data = sequence_data['Power'][TRAIN_SIZE:TRAIN_SIZE+VAL_SIZE]\n",
    "            test_data = sequence_data['Power'][TRAIN_SIZE+VAL_SIZE:TRAIN_SIZE+VAL_SIZE+TEST_SIZE]\n",
    "            \n",
    "            # Train model with modified initialization\n",
    "            model = SARIMAX(\n",
    "                train_data,\n",
    "                order=config['order'],\n",
    "                seasonal_order=config['seasonal_order'],\n",
    "                enforce_stationarity=False,\n",
    "                initialization='approximate',  # Try 'approximate' initialization\n",
    "                trend='c'  # Add constant trend\n",
    "            )\n",
    "            \n",
    "            # Fit with modified settings\n",
    "            fitted_model = model.fit(disp=False,\n",
    "                                   method='powell',  # Change optimizer\n",
    "                                   maxiter=50)      # Limit iterations\n",
    "            \n",
    "            # Make predictions\n",
    "            val_predictions = fitted_model.predict(\n",
    "                start=len(train_data),\n",
    "                end=len(train_data) + len(val_data) - 1,\n",
    "                dynamic=False  # Use actual values for lagged predictions\n",
    "            )\n",
    "            val_predictions = scaler.inverse_transform(val_predictions.reshape(-1, 1)).ravel()\n",
    "            \n",
    "            test_predictions = fitted_model.predict(\n",
    "                start=len(train_data) + len(val_data),\n",
    "                end=len(train_data) + len(val_data) + len(test_data) - 1,\n",
    "                dynamic=True  # Use predicted values for lagged predictions\n",
    "            )\n",
    "            test_predictions = scaler.inverse_transform(test_predictions.reshape(-1, 1)).ravel()\n",
    "            \n",
    "            # Calculate metrics\n",
    "            metrics = {\n",
    "                'val_rmse': np.sqrt(mean_squared_error(val_data, val_predictions)),\n",
    "                'val_mae': mean_absolute_error(val_data, val_predictions),\n",
    "                'test_rmse': np.sqrt(mean_squared_error(test_data, test_predictions)),\n",
    "                'test_mae': mean_absolute_error(test_data, test_predictions)\n",
    "            }\n",
    "            \n",
    "            # Log metrics\n",
    "            mlflow.log_metrics(metrics)\n",
    "            \n",
    "            # Print results\n",
    "            print(f\"\\nResults for {config['name']}:\")\n",
    "            print(f\"Validation RMSE: {metrics['val_rmse']:.4f}\")\n",
    "            print(f\"Test RMSE: {metrics['test_rmse']:.4f}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error in {config['name']}: {str(e)}\")\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b09315-7d12-4804-88b6-69788ac0acbe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61847ad6-2de8-4359-98ef-76ace7b692cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb951926-98db-4c9e-86b6-d4f6a321cc08",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
